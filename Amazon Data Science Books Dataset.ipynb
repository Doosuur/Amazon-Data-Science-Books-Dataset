{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b77404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56ea1c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>price</th>\n",
       "      <th>price (including used books)</th>\n",
       "      <th>pages</th>\n",
       "      <th>avg_reviews</th>\n",
       "      <th>n_reviews</th>\n",
       "      <th>star5</th>\n",
       "      <th>star4</th>\n",
       "      <th>star3</th>\n",
       "      <th>star2</th>\n",
       "      <th>star1</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>weight</th>\n",
       "      <th>language</th>\n",
       "      <th>publisher</th>\n",
       "      <th>ISBN_13</th>\n",
       "      <th>link</th>\n",
       "      <th>complete_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analysis Using R (Low Priced Edition): A ...</td>\n",
       "      <td>[ Dr Dhaval Maheta]</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.75</td>\n",
       "      <td>500</td>\n",
       "      <td>4.4</td>\n",
       "      <td>23</td>\n",
       "      <td>55%</td>\n",
       "      <td>39%</td>\n",
       "      <td>6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5 x 1.01 x 11 inches</td>\n",
       "      <td>2.53 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Notion Press Media Pvt Ltd (November 22, 2021)</td>\n",
       "      <td>978-1685549596</td>\n",
       "      <td>/Data-Analysis-Using-Low-Priced/dp/1685549594/...</td>\n",
       "      <td>https://www.amazon.com/Data-Analysis-Using-Low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Head First Data Analysis: A learner's guide to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.72</td>\n",
       "      <td>21.49 - 33.72</td>\n",
       "      <td>484</td>\n",
       "      <td>4.3</td>\n",
       "      <td>124</td>\n",
       "      <td>61%</td>\n",
       "      <td>20%</td>\n",
       "      <td>9%</td>\n",
       "      <td>4%</td>\n",
       "      <td>6%</td>\n",
       "      <td>8 x 0.98 x 9.25 inches</td>\n",
       "      <td>1.96 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 1st edition (August 18, 2009)</td>\n",
       "      <td>978-0596153939</td>\n",
       "      <td>/Head-First-Data-Analysis-statistics/dp/059615...</td>\n",
       "      <td>https://www.amazon.com/Head-First-Data-Analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guerrilla Data Analysis Using Microsoft Excel:...</td>\n",
       "      <td>[ Oz du Soleil,  and , Bill Jelen]</td>\n",
       "      <td>32.07</td>\n",
       "      <td>32.07</td>\n",
       "      <td>274</td>\n",
       "      <td>4.7</td>\n",
       "      <td>10</td>\n",
       "      <td>87%</td>\n",
       "      <td>13%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.25 x 0.6 x 10.75 inches</td>\n",
       "      <td>1.4 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Holy Macro! Books; Third edition (August 1, 2022)</td>\n",
       "      <td>978-1615470747</td>\n",
       "      <td>/Guerrilla-Analysis-Using-Microsoft-Excel/dp/1...</td>\n",
       "      <td>https://www.amazon.com/Guerrilla-Analysis-Usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python for Data Analysis: Data Wrangling with ...</td>\n",
       "      <td>[ William McKinney]</td>\n",
       "      <td>53.99</td>\n",
       "      <td>53.99</td>\n",
       "      <td>547</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1,686</td>\n",
       "      <td>75%</td>\n",
       "      <td>16%</td>\n",
       "      <td>5%</td>\n",
       "      <td>2%</td>\n",
       "      <td>2%</td>\n",
       "      <td>7 x 1.11 x 9.19 inches</td>\n",
       "      <td>1.47 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 2nd edition (November 14, 2017)</td>\n",
       "      <td>978-1491957660</td>\n",
       "      <td>/Python-Data-Analysis-Wrangling-IPython/dp/149...</td>\n",
       "      <td>https://www.amazon.com/Python-Data-Analysis-Wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excel Data Analysis For Dummies (For Dummies (...</td>\n",
       "      <td>[ Paul McFedries]</td>\n",
       "      <td>24.49</td>\n",
       "      <td>24.49</td>\n",
       "      <td>368</td>\n",
       "      <td>3.9</td>\n",
       "      <td>12</td>\n",
       "      <td>52%</td>\n",
       "      <td>17%</td>\n",
       "      <td>10%</td>\n",
       "      <td>10%</td>\n",
       "      <td>10%</td>\n",
       "      <td>7.38 x 0.83 x 9.25 inches</td>\n",
       "      <td>1.3 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>For Dummies; 5th edition (February 3, 2022)</td>\n",
       "      <td>978-1119844426</td>\n",
       "      <td>/Excel-Data-Analysis-Dummies-Computer/dp/11198...</td>\n",
       "      <td>https://www.amazon.com/Excel-Data-Analysis-Dum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Data Analysis Using R (Low Priced Edition): A ...   \n",
       "1  Head First Data Analysis: A learner's guide to...   \n",
       "2  Guerrilla Data Analysis Using Microsoft Excel:...   \n",
       "3  Python for Data Analysis: Data Wrangling with ...   \n",
       "4  Excel Data Analysis For Dummies (For Dummies (...   \n",
       "\n",
       "                               author  price price (including used books)  \\\n",
       "0                 [ Dr Dhaval Maheta]   6.75                         6.75   \n",
       "1                                 NaN  33.72               21.49 - 33.72    \n",
       "2  [ Oz du Soleil,  and , Bill Jelen]  32.07                        32.07   \n",
       "3                 [ William McKinney]  53.99                        53.99   \n",
       "4                   [ Paul McFedries]  24.49                        24.49   \n",
       "\n",
       "  pages  avg_reviews n_reviews star5 star4 star3 star2 star1  \\\n",
       "0   500          4.4        23   55%   39%    6%   NaN   NaN   \n",
       "1   484          4.3       124   61%   20%    9%    4%    6%   \n",
       "2   274          4.7        10   87%   13%   NaN   NaN   NaN   \n",
       "3   547          4.6     1,686   75%   16%    5%    2%    2%   \n",
       "4   368          3.9        12   52%   17%   10%   10%   10%   \n",
       "\n",
       "                  dimensions       weight language  \\\n",
       "0     8.5 x 1.01 x 11 inches  2.53 pounds  English   \n",
       "1     8 x 0.98 x 9.25 inches  1.96 pounds  English   \n",
       "2  8.25 x 0.6 x 10.75 inches   1.4 pounds  English   \n",
       "3     7 x 1.11 x 9.19 inches  1.47 pounds  English   \n",
       "4  7.38 x 0.83 x 9.25 inches   1.3 pounds  English   \n",
       "\n",
       "                                           publisher         ISBN_13  \\\n",
       "0     Notion Press Media Pvt Ltd (November 22, 2021)  978-1685549596   \n",
       "1      O'Reilly Media; 1st edition (August 18, 2009)  978-0596153939   \n",
       "2  Holy Macro! Books; Third edition (August 1, 2022)  978-1615470747   \n",
       "3    O'Reilly Media; 2nd edition (November 14, 2017)  978-1491957660   \n",
       "4        For Dummies; 5th edition (February 3, 2022)  978-1119844426   \n",
       "\n",
       "                                                link  \\\n",
       "0  /Data-Analysis-Using-Low-Priced/dp/1685549594/...   \n",
       "1  /Head-First-Data-Analysis-statistics/dp/059615...   \n",
       "2  /Guerrilla-Analysis-Using-Microsoft-Excel/dp/1...   \n",
       "3  /Python-Data-Analysis-Wrangling-IPython/dp/149...   \n",
       "4  /Excel-Data-Analysis-Dummies-Computer/dp/11198...   \n",
       "\n",
       "                                       complete_link  \n",
       "0  https://www.amazon.com/Data-Analysis-Using-Low...  \n",
       "1  https://www.amazon.com/Head-First-Data-Analysi...  \n",
       "2  https://www.amazon.com/Guerrilla-Analysis-Usin...  \n",
       "3  https://www.amazon.com/Python-Data-Analysis-Wr...  \n",
       "4  https://www.amazon.com/Excel-Data-Analysis-Dum...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset\n",
    "df = pd.read_csv('final_book_dataset_kaggle2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc796a",
   "metadata": {},
   "source": [
    "### Checking basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483b5b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'author', 'price', 'price (including used books)', 'pages',\n",
       "       'avg_reviews', 'n_reviews', 'star5', 'star4', 'star3', 'star2', 'star1',\n",
       "       'dimensions', 'weight', 'language', 'publisher', 'ISBN_13', 'link',\n",
       "       'complete_link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f44f6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 830 entries, 0 to 829\n",
      "Data columns (total 19 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   title                         830 non-null    object \n",
      " 1   author                        657 non-null    object \n",
      " 2   price                         722 non-null    float64\n",
      " 3   price (including used books)  722 non-null    object \n",
      " 4   pages                         745 non-null    object \n",
      " 5   avg_reviews                   702 non-null    float64\n",
      " 6   n_reviews                     702 non-null    object \n",
      " 7   star5                         702 non-null    object \n",
      " 8   star4                         635 non-null    object \n",
      " 9   star3                         554 non-null    object \n",
      " 10  star2                         451 non-null    object \n",
      " 11  star1                         328 non-null    object \n",
      " 12  dimensions                    644 non-null    object \n",
      " 13  weight                        651 non-null    object \n",
      " 14  language                      759 non-null    object \n",
      " 15  publisher                     714 non-null    object \n",
      " 16  ISBN_13                       665 non-null    object \n",
      " 17  link                          830 non-null    object \n",
      " 18  complete_link                 830 non-null    object \n",
      "dtypes: float64(2), object(17)\n",
      "memory usage: 123.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42f4d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star1                           502\n",
       "star2                           379\n",
       "star3                           276\n",
       "star4                           195\n",
       "dimensions                      186\n",
       "weight                          179\n",
       "author                          173\n",
       "ISBN_13                         165\n",
       "avg_reviews                     128\n",
       "n_reviews                       128\n",
       "star5                           128\n",
       "publisher                       116\n",
       "price (including used books)    108\n",
       "price                           108\n",
       "pages                            85\n",
       "language                         71\n",
       "link                              0\n",
       "title                             0\n",
       "complete_link                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30800576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>star1</th>\n",
       "      <td>60.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star2</th>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star3</th>\n",
       "      <td>33.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star4</th>\n",
       "      <td>23.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions</th>\n",
       "      <td>22.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>21.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>20.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN_13</th>\n",
       "      <td>19.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_reviews</th>\n",
       "      <td>15.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_reviews</th>\n",
       "      <td>15.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star5</th>\n",
       "      <td>15.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher</th>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price (including used books)</th>\n",
       "      <td>13.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>13.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pages</th>\n",
       "      <td>10.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>8.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complete_link</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Percent Missing\n",
       "star1                                   60.48\n",
       "star2                                   45.66\n",
       "star3                                   33.25\n",
       "star4                                   23.49\n",
       "dimensions                              22.41\n",
       "weight                                  21.57\n",
       "author                                  20.84\n",
       "ISBN_13                                 19.88\n",
       "avg_reviews                             15.42\n",
       "n_reviews                               15.42\n",
       "star5                                   15.42\n",
       "publisher                               13.98\n",
       "price (including used books)            13.01\n",
       "price                                   13.01\n",
       "pages                                   10.24\n",
       "language                                 8.55\n",
       "link                                     0.00\n",
       "title                                    0.00\n",
       "complete_link                            0.00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check percentage of missing data\n",
    "missing_data = round(df.isnull().sum().sort_values(ascending = False) * 100/len(df), 2)\n",
    "percent_missing = pd.DataFrame({'Percent Missing' : missing_data})\n",
    "percent_missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ef754d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e091d66f",
   "metadata": {},
   "source": [
    "### Check Object Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8fe125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>price (including used books)</th>\n",
       "      <th>pages</th>\n",
       "      <th>n_reviews</th>\n",
       "      <th>star5</th>\n",
       "      <th>star4</th>\n",
       "      <th>star3</th>\n",
       "      <th>star2</th>\n",
       "      <th>star1</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>weight</th>\n",
       "      <th>language</th>\n",
       "      <th>publisher</th>\n",
       "      <th>ISBN_13</th>\n",
       "      <th>link</th>\n",
       "      <th>complete_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Practical Data Analysis Using Jupyter Notebook...</td>\n",
       "      <td>[ Marc Wintjen,  and , Andrew Vlahutin]</td>\n",
       "      <td>34.99</td>\n",
       "      <td>322</td>\n",
       "      <td>33</td>\n",
       "      <td>56%</td>\n",
       "      <td>16%</td>\n",
       "      <td>7%</td>\n",
       "      <td>10%</td>\n",
       "      <td>11%</td>\n",
       "      <td>7.5 x 0.73 x 9.25 inches</td>\n",
       "      <td>1.22 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Packt Publishing (June 19, 2020)</td>\n",
       "      <td>978-1838826031</td>\n",
       "      <td>/Practical-Analysis-Using-Jupyter-Notebook/dp/...</td>\n",
       "      <td>https://www.amazon.com/Practical-Analysis-Usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>The Pandas Workshop: A comprehensive guide to ...</td>\n",
       "      <td>[ Blaine Bateman, Saikat Basak, et al.]</td>\n",
       "      <td>49.99</td>\n",
       "      <td>744</td>\n",
       "      <td>13</td>\n",
       "      <td>71%</td>\n",
       "      <td>19%</td>\n",
       "      <td>10%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5 x 1.68 x 9.25 inches</td>\n",
       "      <td>2.77 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Packt Publishing (June 17, 2022)</td>\n",
       "      <td>978-1800208933</td>\n",
       "      <td>/gp/slredirect/picassoRedirect.html/ref=pa_sp_...</td>\n",
       "      <td>https://www.amazon.com/gp/slredirect/picassoRe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Become an Awesome Software Architect: Book 1: ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.99</td>\n",
       "      <td>190</td>\n",
       "      <td>87</td>\n",
       "      <td>56%</td>\n",
       "      <td>22%</td>\n",
       "      <td>11%</td>\n",
       "      <td>2%</td>\n",
       "      <td>8%</td>\n",
       "      <td>7.5 x 0.43 x 9.25 inches</td>\n",
       "      <td>12 ounces</td>\n",
       "      <td>English</td>\n",
       "      <td>Independently published (October 7, 2019)</td>\n",
       "      <td>978-1697271065</td>\n",
       "      <td>/gp/slredirect/picassoRedirect.html/ref=pa_sp_...</td>\n",
       "      <td>https://www.amazon.com/gp/slredirect/picassoRe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Scala 3 Programming for Beginners: An Introduc...</td>\n",
       "      <td>[ Nathan Metzler]</td>\n",
       "      <td>8.99</td>\n",
       "      <td>176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 x 0.4 x 9 inches</td>\n",
       "      <td>11.4 ounces</td>\n",
       "      <td>Scroll to the top of the page and click the</td>\n",
       "      <td>Independently published (December 16, 2021)</td>\n",
       "      <td>979-8782427801</td>\n",
       "      <td>/gp/slredirect/picassoRedirect.html/ref=pa_sp_...</td>\n",
       "      <td>https://www.amazon.com/gp/slredirect/picassoRe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Beginner's Guide to Streamlit with Python: Bui...</td>\n",
       "      <td>[ Sujay Raghavendra]</td>\n",
       "      <td>39.45</td>\n",
       "      <td>224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.11 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Apress; 1st ed. edition (January 3, 2023)</td>\n",
       "      <td>978-1484289822</td>\n",
       "      <td>/Beginners-Guide-Streamlit-Python-Applications...</td>\n",
       "      <td>https://www.amazon.com/Beginners-Guide-Streaml...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "148  Practical Data Analysis Using Jupyter Notebook...   \n",
       "197  The Pandas Workshop: A comprehensive guide to ...   \n",
       "615  Become an Awesome Software Architect: Book 1: ...   \n",
       "492  Scala 3 Programming for Beginners: An Introduc...   \n",
       "450  Beginner's Guide to Streamlit with Python: Bui...   \n",
       "\n",
       "                                      author price (including used books)  \\\n",
       "148  [ Marc Wintjen,  and , Andrew Vlahutin]                        34.99   \n",
       "197  [ Blaine Bateman, Saikat Basak, et al.]                        49.99   \n",
       "615                                      NaN                        49.99   \n",
       "492                        [ Nathan Metzler]                         8.99   \n",
       "450                     [ Sujay Raghavendra]                        39.45   \n",
       "\n",
       "    pages n_reviews star5 star4 star3 star2 star1                dimensions  \\\n",
       "148   322        33   56%   16%    7%   10%   11%  7.5 x 0.73 x 9.25 inches   \n",
       "197   744        13   71%   19%   10%   NaN   NaN  7.5 x 1.68 x 9.25 inches   \n",
       "615   190        87   56%   22%   11%    2%    8%  7.5 x 0.43 x 9.25 inches   \n",
       "492   176       NaN   NaN   NaN   NaN   NaN   NaN        6 x 0.4 x 9 inches   \n",
       "450   224       NaN   NaN   NaN   NaN   NaN   NaN                       NaN   \n",
       "\n",
       "          weight                                      language  \\\n",
       "148  1.22 pounds                                       English   \n",
       "197  2.77 pounds                                       English   \n",
       "615    12 ounces                                       English   \n",
       "492  11.4 ounces  Scroll to the top of the page and click the    \n",
       "450  1.11 pounds                                       English   \n",
       "\n",
       "                                       publisher         ISBN_13  \\\n",
       "148             Packt Publishing (June 19, 2020)  978-1838826031   \n",
       "197             Packt Publishing (June 17, 2022)  978-1800208933   \n",
       "615    Independently published (October 7, 2019)  978-1697271065   \n",
       "492  Independently published (December 16, 2021)  979-8782427801   \n",
       "450    Apress; 1st ed. edition (January 3, 2023)  978-1484289822   \n",
       "\n",
       "                                                  link  \\\n",
       "148  /Practical-Analysis-Using-Jupyter-Notebook/dp/...   \n",
       "197  /gp/slredirect/picassoRedirect.html/ref=pa_sp_...   \n",
       "615  /gp/slredirect/picassoRedirect.html/ref=pa_sp_...   \n",
       "492  /gp/slredirect/picassoRedirect.html/ref=pa_sp_...   \n",
       "450  /Beginners-Guide-Streamlit-Python-Applications...   \n",
       "\n",
       "                                         complete_link  \n",
       "148  https://www.amazon.com/Practical-Analysis-Usin...  \n",
       "197  https://www.amazon.com/gp/slredirect/picassoRe...  \n",
       "615  https://www.amazon.com/gp/slredirect/picassoRe...  \n",
       "492  https://www.amazon.com/gp/slredirect/picassoRe...  \n",
       "450  https://www.amazon.com/Beginners-Guide-Streaml...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_variables = df.select_dtypes(object).sample(5)\n",
    "obj_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d64a6b",
   "metadata": {},
   "source": [
    "### STEPS TO TAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f0bd4",
   "metadata": {},
   "source": [
    "1. Replace missing values in the `pages` column with 0 and clean the column\n",
    "\n",
    "2. Rename the `price (including used books)` column, replace NAN values with the average, and clean the column\n",
    "\n",
    "3. Remove the ` [ ` and ` ] ` and any other characters from the `author` column and replace the missing values\n",
    "\n",
    "4. Clean the `n_reviews` columns.\n",
    "\n",
    "5. Clean the `star` columns\n",
    "\n",
    "6. Convert the `dimensions` column to cm and replace null values with 0\n",
    "\n",
    "7. convert all other units of measurements in the `weight` column to kg and replace null values\n",
    "\n",
    "8. Split the rows in `publisher` column with dates to another column and replace null values\n",
    "\n",
    "9. Clean the `Language` Column\n",
    "\n",
    "10. Drop unnecessary columns \n",
    "\n",
    "11. Replace missing values in other columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed45f6b",
   "metadata": {},
   "source": [
    "### 1. Replace missing values in the `pages` column with the 0 and clean the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e368f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444    358\n",
       "53     384\n",
       "546    590\n",
       "300    534\n",
       "63     384\n",
       "584    328\n",
       "756    NaN\n",
       "174    300\n",
       "296    288\n",
       "93     222\n",
       "741    134\n",
       "324    381\n",
       "677    166\n",
       "201    566\n",
       "260    162\n",
       "Name: pages, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pages'].sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f7709",
   "metadata": {},
   "source": [
    "The datatype for the pages column is object. Let's check to see why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841082c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df['pages'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e910686",
   "metadata": {},
   "source": [
    "Some values are in string format so we'll convert them to a numeric type and fill them with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c19ffbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert non-integer values to numeric\n",
    "df['pages'] = pd.to_numeric(df['pages'], errors = 'coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89116fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fill missing values with 0\n",
    "df['pages'].fillna('0', inplace = True)\n",
    "df['pages'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b895c8",
   "metadata": {},
   "source": [
    "### 2. Rename the `price (including used books)` column, replace NAN values with the average, and clean the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf7b6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'price (including used books)':'all_prices'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd72eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11                15.97\n",
       "270               44.99\n",
       "738                 NaN\n",
       "629      16.57 - 46.99 \n",
       "318                3.99\n",
       "600               19.99\n",
       "15                24.99\n",
       "337     19.50 - 146.65 \n",
       "335      43.99 - 48.49 \n",
       "585      13.99 - 17.39 \n",
       "305               35.67\n",
       "538      45.16 - 50.23 \n",
       "658              119.21\n",
       "153                  37\n",
       "324               23.74\n",
       "Name: all_prices, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['all_prices'].sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f86e4",
   "metadata": {},
   "source": [
    "There are certain values in the all_prices column that reflect the costs of both new and used books. We'll calculate the average of these numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be40249f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14      39.99\n",
       "32       0.99\n",
       "695    124.55\n",
       "238     34.22\n",
       "664     17.49\n",
       "772     40.66\n",
       "341       NaN\n",
       "75      40.50\n",
       "25      29.99\n",
       "580     16.38\n",
       "323     25.43\n",
       "638    743.47\n",
       "173     78.72\n",
       "31      13.99\n",
       "204     88.28\n",
       "Name: average_value, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract the minimum and maximum values from range values and compute their average\n",
    "def price_average(val):\n",
    "    if isinstance(val, str) and '-' in val:\n",
    "        min_value, max_value = map(float, val.split('-'))\n",
    "        return round((min_value + max_value) / 2, 2)\n",
    "    else:\n",
    "        try:\n",
    "            return float(val)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "# Apply the function to the column and create a new column\n",
    "df['average_value'] = df['all_prices'].apply(price_average)\n",
    "\n",
    "# check updated column\n",
    "df['average_value'].sample(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64ad535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the average_value column with the mean\n",
    "df['average_value'].fillna(df['average_value'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5db699b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Round to 2 decimal places\n",
    "df['average_value'] = np.round(df['average_value'], decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573fb254",
   "metadata": {},
   "source": [
    "### 3. Remove the ` [ ` and ` ] `brackets and any other characters from the `author` column and replace the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7447e4b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779                               [ David Ping]\n",
       "819                   [ Jacqueline M. Quinless]\n",
       "179                                         NaN\n",
       "563                             [ Eric Matthes]\n",
       "406                                         NaN\n",
       "781                       [ Thorsten Gressling]\n",
       "167                                         NaN\n",
       "277                                         NaN\n",
       "81                           [ Rupert Morrison]\n",
       "3                           [ William McKinney]\n",
       "647                                         NaN\n",
       "434                         [ Abdullah Karasan]\n",
       "352    [ Matt Harrison,  and , Theodore Petrou]\n",
       "721                              [ Chirag Shah]\n",
       "461                                         NaN\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d760ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to strip the '[' and ']' brackets\n",
    "def author_col(x):\n",
    "    if x == x:\n",
    "        return x.lstrip('[ ').rstrip(']').replace(',  and ,', ' and')\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "df['author'] = df['author'].apply(author_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee410d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "817                                         NaN\n",
       "388                                         NaN\n",
       "605                                Rafal Leszko\n",
       "465    V Kishore Ayyadevara and Yeshwanth Reddy\n",
       "683                              Jeremy Adamson\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8542fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing values with 'No Name'\n",
    "df['author'].fillna('No Name', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea43fd",
   "metadata": {},
   "source": [
    "### 4. Clean the `n_reviews` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78358089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409      126\n",
       "412      NaN\n",
       "38        26\n",
       "778    7,953\n",
       "211       12\n",
       "214    1,984\n",
       "147        7\n",
       "114       10\n",
       "434        8\n",
       "460       71\n",
       "36        13\n",
       "440      905\n",
       "383        1\n",
       "695        1\n",
       "774      NaN\n",
       "Name: n_reviews, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_reviews'].sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ecd7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['n_reviews'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a7cc7",
   "metadata": {},
   "source": [
    "Values in thousands have a comma. We'll remove the commas to make them integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caf57a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace commas in string values and leave NaN values as they are\n",
    "df['n_reviews'] = df['n_reviews'].apply(lambda x: str(x).replace(',', '') if type(x)==str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39f897e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250      91\n",
       "636      87\n",
       "348      78\n",
       "329     580\n",
       "610      64\n",
       "463      84\n",
       "179    1155\n",
       "591     591\n",
       "614       0\n",
       "359       0\n",
       "Name: n_reviews, dtype: int32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to integer data type and replace null values with 0\n",
    "df['n_reviews'] = pd.to_numeric(df['n_reviews'], errors = 'coerce').fillna(0).astype(int)\n",
    "df['n_reviews'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809313f",
   "metadata": {},
   "source": [
    "### 5. Clean the star column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a2d7d",
   "metadata": {},
   "source": [
    "Fill the null values in star columns with 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbbffa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['star5', 'star4', 'star3', 'star2', 'star1']:\n",
    "    df[column].fillna('0', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e5c9687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star5</th>\n",
       "      <th>star4</th>\n",
       "      <th>star3</th>\n",
       "      <th>star2</th>\n",
       "      <th>star1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>70%</td>\n",
       "      <td>22%</td>\n",
       "      <td>8%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>69%</td>\n",
       "      <td>17%</td>\n",
       "      <td>5%</td>\n",
       "      <td>3%</td>\n",
       "      <td>6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>65%</td>\n",
       "      <td>26%</td>\n",
       "      <td>4%</td>\n",
       "      <td>3%</td>\n",
       "      <td>3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>69%</td>\n",
       "      <td>13%</td>\n",
       "      <td>7%</td>\n",
       "      <td>4%</td>\n",
       "      <td>6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>57%</td>\n",
       "      <td>23%</td>\n",
       "      <td>8%</td>\n",
       "      <td>11%</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>61%</td>\n",
       "      <td>12%</td>\n",
       "      <td>12%</td>\n",
       "      <td>7%</td>\n",
       "      <td>7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>100%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    star5 star4 star3 star2 star1\n",
       "292   70%   22%    8%     0     0\n",
       "104   69%   17%    5%    3%    6%\n",
       "464   65%   26%    4%    3%    3%\n",
       "337   69%   13%    7%    4%    6%\n",
       "450     0     0     0     0     0\n",
       "369   57%   23%    8%   11%     0\n",
       "796   61%   12%   12%    7%    7%\n",
       "345  100%     0     0     0     0\n",
       "87      0     0     0     0     0\n",
       "185     0     0     0     0     0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['star5', 'star4', 'star3', 'star2', 'star1']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c466154",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['star5', 'star4', 'star3', 'star2', 'star1']\n",
    "def strip_and_convert_to_float(df, column_name):\n",
    "   \n",
    "    df[column_name] = df[column_name].str.rstrip('%').astype(float) / 10\n",
    "    \n",
    "for column in columns_to_convert:\n",
    "        strip_and_convert_to_float(df, column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84a7a308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star5</th>\n",
       "      <th>star4</th>\n",
       "      <th>star3</th>\n",
       "      <th>star2</th>\n",
       "      <th>star1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>7.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     star5  star4  star3  star2  star1\n",
       "29     7.0    3.0    0.0    0.0    0.0\n",
       "663    9.0    1.0    0.0    0.0    0.0\n",
       "196    6.3    2.0    0.4    0.8    0.5\n",
       "212   10.0    0.0    0.0    0.0    0.0\n",
       "572    7.6    1.1    0.5    0.8    0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['star5', 'star4', 'star3', 'star2', 'star1']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b06b2",
   "metadata": {},
   "source": [
    "### 6. Convert the dimensions column to cm and replace null values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "794a27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['dimensions'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db369094",
   "metadata": {},
   "source": [
    "Some of the dimension also have their weights attached to the dimensions so we'll split the rows having weight and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "788aae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['book_dimensions', 'book_weight']] = df['dimensions'].str.split(';', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acb241f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, nan, ' 3.2 Ounces', ' 7.37 Ounces', ' 1.8 Pounds',\n",
       "       ' 1.5 Pounds', ' 1.13 Ounces', ' 8.47 Ounces', ' 2.72 Ounces',\n",
       "       ' 1.6 Ounces', ' 4 Ounces', ' 2.4 Ounces'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['book_weight'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d38f5085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269           10 x 2 x 12 \n",
       "615     7.5 x 0.43 x 9.25 \n",
       "435     7.4 x 1.15 x 8.95 \n",
       "86     7.38 x 0.69 x 9.25 \n",
       "304                    NaN\n",
       "351     7.25 x 0.75 x 9.5 \n",
       "372       7.4 x 1.6 x 9.1 \n",
       "489     7.5 x 0.82 x 9.25 \n",
       "74     6.25 x 0.75 x 9.25 \n",
       "749                    NaN\n",
       "Name: book_dimensions, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the inches unit of measurement\n",
    "df['book_dimensions'] = df['book_dimensions'].str.rstrip('inches')\n",
    "df['book_dimensions'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22c450cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define function to convert inches to cm\n",
    "def convert_to_cm(val):\n",
    "    if isinstance(val, str):\n",
    "        \n",
    "        # Extract numeric values from the string\n",
    "        nums = [float(x) for x in val.split('x')]\n",
    "        \n",
    "        # Multiply values by 2.54 to convert to cm\n",
    "        return round(np.prod(nums) * 2.54, 2)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply conversion function to column\n",
    "df['book_dimensions(cm)'] = df['book_dimensions'].apply(convert_to_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c0589b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272     94.31\n",
       "367    181.05\n",
       "686    135.91\n",
       "829       NaN\n",
       "827    114.54\n",
       "536    210.66\n",
       "625     27.40\n",
       "652    170.34\n",
       "595     32.92\n",
       "240    109.25\n",
       "Name: book_dimensions(cm), dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['book_dimensions(cm)'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "511ab296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_dimensions(cm)'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1dd6423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240    109.25\n",
       "706    173.75\n",
       "318      0.00\n",
       "148    128.64\n",
       "134      0.00\n",
       "Name: book_dimensions(cm), dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['book_dimensions(cm)'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ce1b52",
   "metadata": {},
   "source": [
    "### 7. convert all other units of measurements in the weight column with pounds and replace null values with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc05ecfa",
   "metadata": {},
   "source": [
    "We'll check if the book_weight column we created earlier matches any missing values in the weight columnso that the missing values in the weight column can be replaced with values from the book_weight column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ddfe448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "\n",
    "#df[['weight', 'book_weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98024102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weight'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "add80854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'].fillna(df['book_weight'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98cb1370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weight'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ee9c0ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795     0.6\n",
       "36     0.37\n",
       "207     0.5\n",
       "140    0.49\n",
       "195    1.43\n",
       "496    0.95\n",
       "135    1.86\n",
       "447    0.94\n",
       "585    0.52\n",
       "280     1.3\n",
       "Name: weight, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to convert ounces to pounds\n",
    "def convert_to_pounds(val):\n",
    "    if isinstance(val, str) and 'ounces' in val:\n",
    "        ounces = float(val.split()[0])\n",
    "        return round(ounces * 0.0283495, 2)\n",
    "    elif isinstance(val, str) and 'pounds' in val:\n",
    "        pounds = float(val.split()[0])\n",
    "        return round(pounds * 0.453592, 2)\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "# apply the function to the 'Weight' column\n",
    "df['weight'] = df['weight'].apply(convert_to_pounds)\n",
    "\n",
    "df['weight'].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf390db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the column to numeric type and fill null values with 0.\n",
    "df['weight'] = pd.to_numeric(df['weight'], errors = 'coerce').fillna(0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c329c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Round to 2 decimal places\n",
    "df['weight'] = np.round(df['weight'], decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741de164",
   "metadata": {},
   "source": [
    "### 8. Split the rows in publisher column with date to another column and replace null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86336790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11          Independently published (September 21, 2022)\n",
       "102    Swedish Pharmaceutical Press; 5th edition (Jan...\n",
       "263                 Packt Publishing (December 16, 2022)\n",
       "667                       The MIT Press (April 18, 2023)\n",
       "261      Springer; 6th ed. 2021 edition (March 16, 2021)\n",
       "353            Independently published (October 6, 2020)\n",
       "811    A K Peters/CRC Press; 1st edition (February 9,...\n",
       "465                 Packt Publishing (November 27, 2020)\n",
       "394             Independently published (April 28, 2018)\n",
       "161    Holy Macro! Books; Second Edition, Second edit...\n",
       "685    Chapman and Hall/CRC; 1st edition (November 30...\n",
       "434      O'Reilly Media; 1st edition (December 28, 2021)\n",
       "232    Chapman and Hall/CRC; 2nd edition (April 18, 2...\n",
       "191          Academic Press; 2nd edition (June 15, 2023)\n",
       "401                                                  NaN\n",
       "Name: publisher, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['publisher'].sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a3322ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Publisher\" column by the first opening parenthesis\n",
    "df[['Publisher', 'Publication Date']] = df['publisher'].str.split('(', 1, expand=True)\n",
    "\n",
    "# Extract the date and remove the closing parenthesis\n",
    "df['Publication Date'] = df['Publication Date'].str.rstrip(')')\n",
    "\n",
    "# convert Publication Date column to datetime format\n",
    "df['Publication Date'] = pd.to_datetime(df['Publication Date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efd80543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2021-11-22\n",
       "1   2009-08-18\n",
       "2   2022-08-01\n",
       "3   2017-11-14\n",
       "4   2022-02-03\n",
       "Name: Publication Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Publication Date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b12a3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Notion Press Media Pvt Ltd \n",
       "1         O'Reilly Media; 1st edition \n",
       "2    Holy Macro! Books; Third edition \n",
       "3         O'Reilly Media; 2nd edition \n",
       "4            For Dummies; 5th edition \n",
       "Name: Publisher, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace null values in publisher with 'No Name'\n",
    "df['Publisher'].fillna('No Name', inplace = True)\n",
    "df['Publisher'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c614b5d",
   "metadata": {},
   "source": [
    "### 9. Clean the `Language` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c50a84b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', nan, 'Spanish',\n",
       "       'Unqualified, Japanese (Dolby Digital 2.0 Mono), English (Dolby Digital 5.1), English (Dolby Digital 2.0 Mono)',\n",
       "       'you will discover all you need ',\n",
       "       ' How to make better business decisions using ',\n",
       "       'Concepts are presented in a \"to-the-point\" style to cater to the busy individual. With this book, you can learn Python in just one day and start coding immediately. ',\n",
       "       'standard library',\n",
       "       'This Python programming guide assumes certain level of programming knowledge. It is not a beginner textbook.',\n",
       "       'Scroll to the top of the page and click the ',\n",
       "       'English (Dolby Digital 2.0 Mono)',\n",
       "       'English (DTS-HD Master Audio 5.1), French (DTS-HD 2.0)',\n",
       "       '\"Brilliant.\"'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "370d22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'].fillna('No Language', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "016ca396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to return English, Spanish, and Other for rows that start with ech one respectively.\n",
    "def lang(val):\n",
    "    if val.startswith('English'):\n",
    "        return 'English'\n",
    "    elif val.startswith('Spanish'):\n",
    "        return 'Spanish'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['language'] = df['language'].apply(lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d403ae83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', 'Other', 'Spanish'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62456e7",
   "metadata": {},
   "source": [
    "### 10. Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3684cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['link', 'complete_link', 'publisher', 'dimensions', 'all_prices','book_weight', 'book_dimensions'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95901c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>ISBN_13</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Hands-On Data Science with R: Techniques to pe...</td>\n",
       "      <td>Vitor Bianchi Lanzetta, Nataraj Dasgupta, et al.</td>\n",
       "      <td>English</td>\n",
       "      <td></td>\n",
       "      <td>Packt Publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>Data Science (The MIT Press Essential Knowledg...</td>\n",
       "      <td>No Name</td>\n",
       "      <td>English</td>\n",
       "      <td>99</td>\n",
       "      <td>The MIT Press; Illustrated edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Data-Driven HR: How to Use Analytics and Metri...</td>\n",
       "      <td>Bernard Marr</td>\n",
       "      <td>English</td>\n",
       "      <td>978-0749482466</td>\n",
       "      <td>Kogan Page; 1st edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Calling Bullshit: The Art of Skepticism in a D...</td>\n",
       "      <td>Carl T. Bergstrom and Jevin D. West</td>\n",
       "      <td>English</td>\n",
       "      <td>978-0525509202</td>\n",
       "      <td>Random House Trade Paperbacks; Reprint edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Hands-On Data Analysis in R for Finance</td>\n",
       "      <td>Jean-Francois Collard</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chapman and Hall/CRC; 1st edition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "188  Hands-On Data Science with R: Techniques to pe...   \n",
       "824  Data Science (The MIT Press Essential Knowledg...   \n",
       "196  Data-Driven HR: How to Use Analytics and Metri...   \n",
       "752  Calling Bullshit: The Art of Skepticism in a D...   \n",
       "145            Hands-On Data Analysis in R for Finance   \n",
       "\n",
       "                                               author language  \\\n",
       "188  Vitor Bianchi Lanzetta, Nataraj Dasgupta, et al.  English   \n",
       "824                                           No Name  English   \n",
       "196                                      Bernard Marr  English   \n",
       "752               Carl T. Bergstrom and Jevin D. West  English   \n",
       "145                             Jean-Francois Collard  English   \n",
       "\n",
       "            ISBN_13                                        Publisher  \n",
       "188                                                Packt Publishing   \n",
       "824              99              The MIT Press; Illustrated edition   \n",
       "196  978-0749482466                         Kogan Page; 1st edition   \n",
       "752  978-0525509202  Random House Trade Paperbacks; Reprint edition   \n",
       "145             NaN               Chapman and Hall/CRC; 1st edition   "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_var = df.select_dtypes(object).sample(5)\n",
    "obj_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e96afb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                    0\n",
       "author                   0\n",
       "price                  108\n",
       "pages                    0\n",
       "avg_reviews            128\n",
       "n_reviews                0\n",
       "star5                    0\n",
       "star4                    0\n",
       "star3                    0\n",
       "star2                    0\n",
       "star1                    0\n",
       "weight                   0\n",
       "language                 0\n",
       "ISBN_13                165\n",
       "average_value            0\n",
       "book_dimensions(cm)      0\n",
       "Publisher                0\n",
       "Publication Date       119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4629dc",
   "metadata": {},
   "source": [
    "### 11. Replace Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70e410fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing values appropriately\n",
    "df['avg_reviews'].fillna(df['avg_reviews'].mean(), inplace = True)\n",
    "df['price'].fillna(0, inplace = True)\n",
    "df['price'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e568c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                    0\n",
       "author                   0\n",
       "price                    0\n",
       "pages                    0\n",
       "avg_reviews              0\n",
       "n_reviews                0\n",
       "star5                    0\n",
       "star4                    0\n",
       "star3                    0\n",
       "star2                    0\n",
       "star1                    0\n",
       "weight                   0\n",
       "language                 0\n",
       "ISBN_13                165\n",
       "average_value            0\n",
       "book_dimensions(cm)      0\n",
       "Publisher                0\n",
       "Publication Date       119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3baa959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 830 entries, 0 to 829\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   title                830 non-null    object        \n",
      " 1   author               830 non-null    object        \n",
      " 2   price                830 non-null    float64       \n",
      " 3   pages                830 non-null    int32         \n",
      " 4   avg_reviews          830 non-null    float64       \n",
      " 5   n_reviews            830 non-null    int32         \n",
      " 6   star5                830 non-null    float64       \n",
      " 7   star4                830 non-null    float64       \n",
      " 8   star3                830 non-null    float64       \n",
      " 9   star2                830 non-null    float64       \n",
      " 10  star1                830 non-null    float64       \n",
      " 11  weight               830 non-null    float64       \n",
      " 12  language             830 non-null    object        \n",
      " 13  ISBN_13              665 non-null    object        \n",
      " 14  average_value        830 non-null    float64       \n",
      " 15  book_dimensions(cm)  830 non-null    float64       \n",
      " 16  Publisher            830 non-null    object        \n",
      " 17  Publication Date     711 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(10), int32(2), object(5)\n",
      "memory usage: 110.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
